{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e869b6fa-2596-4ca5-bf29-9dbec4226a41",
   "metadata": {
    "executionInfo": {
     "elapsed": 125,
     "status": "ok",
     "timestamp": 1654799125401,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "e869b6fa-2596-4ca5-bf29-9dbec4226a41"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import (classification_report, multilabel_confusion_matrix, \n",
    "                             accuracy_score, recall_score, precision_score, \n",
    "                             f1_score, classification_report, ConfusionMatrixDisplay)\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical, model_to_dot, plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "\n",
    "colab = True  # Type True if using Google Colab, type False if using Jupyter Notebook\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    from zipfile import ZipFile\n",
    "\n",
    "tensorflow.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40274214-5a83-477a-8ba4-d1dd57a4cffa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16373,
     "status": "ok",
     "timestamp": 1654787564067,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "40274214-5a83-477a-8ba4-d1dd57a4cffa",
    "outputId": "0b7e5cd9-f3f5-43f5-cad2-83fb15c1056e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mounting Google Drive for use with Google Colab\n",
    "\n",
    "if colab:\n",
    "    drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f97652-cb31-4652-958a-b24d2075d677",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11372,
     "status": "ok",
     "timestamp": 1654787577151,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "f0f97652-cb31-4652-958a-b24d2075d677",
    "outputId": "0a715a17-f1c8-4a46-a7f2-64c009800e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped Train Images file\n"
     ]
    }
   ],
   "source": [
    "# Creating file paths for use with Google Colab\n",
    "if colab:\n",
    "    images = 'drive/MyDrive/dog_breed_classifier/Images.zip'\n",
    "\n",
    "    with ZipFile(images, 'r') as train_images:\n",
    "        train_images.extractall()\n",
    "        print('Unzipped Train Images file')\n",
    "\n",
    "if colab:\n",
    "    train_data_dir = './Images'\n",
    "else:\n",
    "    train_data_dir = './Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "VR-8fB6rBww1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1993,
     "status": "ok",
     "timestamp": 1654787720767,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "VR-8fB6rBww1",
    "outputId": "8d718b61-e8e8-496a-d6bb-843c546b5c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped testing Images file\n"
     ]
    }
   ],
   "source": [
    "if colab:\n",
    "    images = 'drive/MyDrive/dog_breed_classifier/Testing_images.zip'\n",
    "\n",
    "    with ZipFile(images, 'r') as train_images:\n",
    "        train_images.extractall()\n",
    "        print('Unzipped testing Images file')\n",
    "\n",
    "if colab:\n",
    "    test_data_dir = './Testing_images'\n",
    "else:\n",
    "    train_data_dir = './Testing_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8au1fj33l5f6",
   "metadata": {
    "id": "8au1fj33l5f6"
   },
   "source": [
    "## Setting up training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d270f65-d700-4265-8c34-4d55d6056c18",
   "metadata": {
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1654788885198,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "4d270f65-d700-4265-8c34-4d55d6056c18"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224 \n",
    "channels = 3\n",
    "batch_size = 64\n",
    "num_images= 50\n",
    "image_arr_size= img_width * img_height * channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e2540ab-05c0-47cf-ba50-84bfd3ee859d",
   "metadata": {
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1654788886943,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "6e2540ab-05c0-47cf-ba50-84bfd3ee859d"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    shear_range= 0.2,\n",
    "    zoom_range= 0.2,\n",
    "    horizontal_flip= True,\n",
    "    rotation_range= 20,\n",
    "    width_shift_range= 0.2,\n",
    "    height_shift_range= 0.2,   \n",
    "    validation_split=0.2,\n",
    "\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255, \n",
    "    validation_split=0.2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5b184b-6d35-411a-9dc3-211a40650650",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1760,
     "status": "ok",
     "timestamp": 1654788891342,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "8d5b184b-6d35-411a-9dc3-211a40650650",
    "outputId": "87debe9c-1d9b-4ac7-e777-d0855372d38a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17230 images belonging to 120 classes.\n",
      "Found 4255 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(  \n",
    "    train_data_dir,  \n",
    "    target_size= (img_width, img_height), \n",
    "    color_mode= 'rgb',\n",
    "    batch_size= batch_size,  \n",
    "    class_mode= 'categorical',\n",
    "    subset='training',\n",
    "    shuffle= True, \n",
    "    seed= 1337\n",
    ") \n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size= (img_width, img_height),\n",
    "    color_mode= 'rgb',\n",
    "    batch_size= batch_size,  \n",
    "    class_mode= 'categorical',\n",
    "    subset='validation',\n",
    "    shuffle= True, \n",
    "    seed= 1337\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d41a136-1fdf-4483-8b53-e17eafc1a744",
   "metadata": {
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1654789197339,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "8d41a136-1fdf-4483-8b53-e17eafc1a744"
   },
   "outputs": [],
   "source": [
    "num_classes = len(train_generator.class_indices)  \n",
    "train_labels = train_generator.classes \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "valid_labels = valid_generator.classes \n",
    "valid_labels = to_categorical(valid_labels, num_classes=num_classes)\n",
    "nb_train_samples = len(train_generator.filenames)  \n",
    "nb_valid_samples = len(valid_generator.filenames)\n",
    "breeds = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J75pMPKxmHxC",
   "metadata": {
    "id": "J75pMPKxmHxC"
   },
   "source": [
    "#### Let's look at the dog breed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "R4pHK0xe7tIF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1654789199807,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "R4pHK0xe7tIF",
    "outputId": "487f9fea-c67a-4665-80a1-27d09e80a2f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 120 breeds in the dataset\n",
      "The breeds include:  ['Affenpinscher', 'Afghan', 'African Wild Dog', 'Airedale', 'American Staffordshire Terrier', 'Appenzeller', 'Australian Terrier', 'Basenji', 'Basset', 'Beagle', 'Bedlington Terrier', 'Bernese Mountain Dog', 'Black-and-Tan Coonhound', 'Blenheim Spaniel', 'Bloodhound', 'Bluetick', 'Border Collie', 'Border Terrier', 'Borzoi', 'Boston Bull', 'Bouvier Des Flandres', 'Boxer', 'Brabancon Griffon', 'Briard', 'Brittany Spaniel', 'Bull Mastiff', 'Cairn', 'Cardigan', 'Chesapeake Bay Retriever', 'Chihuahua', 'Chow', 'Clumber', 'Cocker Spaniel', 'Collie', 'Curly Coated Retriever', 'Dandie Dinmont', 'Dhole', 'Dingo', 'Doberman', 'English Foxhound', 'English Setter', 'English Springer', 'Entlebucher', 'Eskimo Dog', 'Flat Coated Retriever', 'French Bulldog', 'German Shepherd', 'German Short Haired Pointer', 'Giant Schnauzer', 'Golden Retriever', 'Gordon Setter', 'Great Dane', 'Great Pyrenees', 'Greater Swiss Mountain Dog', 'Groenendael', 'Ibizan Hound', 'Irish Setter', 'Irish Terrier', 'Irish Water Spaniel', 'Irish Wolfhound', 'Italian Greyhound', 'Japanese Spaniel', 'Keeshond', 'Kelpie', 'Kerry Blue Terrier', 'Komondor', 'Kuvasz', 'Labrador Retriever', 'Lakeland Terrier', 'Leonberg', 'Lhasa', 'Malamute', 'Malinois', 'Maltese', 'Mexican Hairless', 'Miniature Poodle', 'Miniature Schnauzer', 'Newfoundland', 'Norfolk Terrier', 'Norwegian Elkhound', 'Norwich Terrier', 'Old English Sheepdog', 'Otterhound', 'Papillon', 'Pekinese', 'Pembroke Corgi', 'Pinscher', 'Pomeranian', 'Pug', 'Redbone', 'Rhodesian Ridgeback', 'Rottweiler', 'Saint Bernard', 'Saluki', 'Samoyed', 'Schipperke', 'Scotch Terrier', 'Scottish Deerhound', 'Sealyham Terrier', 'Shetland Sheepdog', 'Shih-Tzu', 'Siberian Husky', 'Silky Terrier', 'Soft Coated Wheaten Terrier', 'Staffordshire Bullterrier', 'Standard Poodle', 'Standard Schnauzer', 'Sussex Spaniel', 'Tibetan Mastiff', 'Tibetan Terrier', 'Toy Poodle', 'Toy Terrier', 'Vizsla', 'Walker Hound', 'Weimaraner', 'Welsh Springer Spaniel', 'West Highland White Terrier', 'Whippet', 'Wire Haired Fox Terrier', 'Yorkshire Terrier']\n"
     ]
    }
   ],
   "source": [
    "print(f'There are a total of {num_classes} breeds in the dataset')\n",
    "print('The breeds include: ', breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa0b8f1-83b1-4cd9-9542-aa39abc62ff2",
   "metadata": {
    "id": "efa0b8f1-83b1-4cd9-9542-aa39abc62ff2"
   },
   "source": [
    "## Model Setup \n",
    "\n",
    "We are using a pre-trained model called InceptionV3, which is an image recognition model which has been shown to attain greater than 78% accuracy on the ImageNet dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88262c01-ff74-4e6d-b990-c65ef56e29ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4273,
     "status": "ok",
     "timestamp": 1654789228560,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "88262c01-ff74-4e6d-b990-c65ef56e29ef",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7e5d6e71-bf92-4a9b-959b-9afb21cd99f7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n",
      "87924736/87910968 [==============================] - 0s 0us/step\n",
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 111, 111, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 54, 54, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "InceptionV3 = applications.InceptionV3(include_top= False, input_shape= (img_width, img_height, channels), weights= 'imagenet')\n",
    "InceptionV3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fzlHq-Zrpl7e",
   "metadata": {
    "id": "fzlHq-Zrpl7e"
   },
   "source": [
    "Below, I will be 'freezing' the layers from InceptionV3, this is done to avoid destroying any of the information they contrain during future training rouncs. \n",
    "\n",
    "We are also adding a GlobalAveragePooling layer and a dropout layer for regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "InwpnCeABpbR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1654789239846,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "InwpnCeABpbR",
    "outputId": "04598d47-16a6-4193-9821-6a7e870892ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               245880    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,048,664\n",
      "Trainable params: 245,880\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "for layer in InceptionV3.layers:\n",
    "    layer.trainable= False\n",
    "    \n",
    "model.add(InceptionV3)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(120,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce72191d-6846-4a14-a3d8-c5090ab03623",
   "metadata": {
    "id": "ce72191d-6846-4a14-a3d8-c5090ab03623"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b761212-d90a-4e46-bfc7-83068e6af8b3",
   "metadata": {
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1654789243036,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "2b761212-d90a-4e46-bfc7-83068e6af8b3"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= keras.optimizers.Adam(learning_rate= 0.0001), loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FHi3tKXvs78c",
   "metadata": {
    "id": "FHi3tKXvs78c"
   },
   "source": [
    "We are further adding early stop as well as reduceLR to avoid overfitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1978694f-2538-49b8-a3f8-8af220750cec",
   "metadata": {
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1654789245646,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "1978694f-2538-49b8-a3f8-8af220750cec"
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=3,\n",
    "    verbose=1, \n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "callbacks = [earlystop, reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "050b8fee-a8ad-4988-9f5f-01b3ffb1ec97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7760727,
     "status": "ok",
     "timestamp": 1654797010160,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "050b8fee-a8ad-4988-9f5f-01b3ffb1ec97",
    "outputId": "c317aefd-dae4-4f8d-cb40-74b29459064e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "269/269 [==============================] - 297s 1s/step - loss: 3.4171 - accuracy: 0.2852 - val_loss: 1.6684 - val_accuracy: 0.7031 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "269/269 [==============================] - 296s 1s/step - loss: 1.5400 - accuracy: 0.6444 - val_loss: 0.9430 - val_accuracy: 0.7725 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "269/269 [==============================] - 294s 1s/step - loss: 1.1436 - accuracy: 0.7002 - val_loss: 0.7802 - val_accuracy: 0.7841 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "269/269 [==============================] - 373s 1s/step - loss: 0.9930 - accuracy: 0.7242 - val_loss: 0.7156 - val_accuracy: 0.7955 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "269/269 [==============================] - 378s 1s/step - loss: 0.9376 - accuracy: 0.7348 - val_loss: 0.6837 - val_accuracy: 0.7985 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "269/269 [==============================] - 379s 1s/step - loss: 0.8895 - accuracy: 0.7418 - val_loss: 0.6675 - val_accuracy: 0.8004 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "269/269 [==============================] - 380s 1s/step - loss: 0.8630 - accuracy: 0.7462 - val_loss: 0.6524 - val_accuracy: 0.8023 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "269/269 [==============================] - 379s 1s/step - loss: 0.8535 - accuracy: 0.7451 - val_loss: 0.6462 - val_accuracy: 0.8049 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "269/269 [==============================] - 379s 1s/step - loss: 0.8210 - accuracy: 0.7561 - val_loss: 0.6448 - val_accuracy: 0.8085 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "269/269 [==============================] - 380s 1s/step - loss: 0.7958 - accuracy: 0.7634 - val_loss: 0.6432 - val_accuracy: 0.8120 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "269/269 [==============================] - 384s 1s/step - loss: 0.7811 - accuracy: 0.7628 - val_loss: 0.6326 - val_accuracy: 0.8061 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "269/269 [==============================] - 382s 1s/step - loss: 0.7706 - accuracy: 0.7656 - val_loss: 0.6361 - val_accuracy: 0.8071 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "269/269 [==============================] - 388s 1s/step - loss: 0.7590 - accuracy: 0.7725 - val_loss: 0.6296 - val_accuracy: 0.8075 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "269/269 [==============================] - 385s 1s/step - loss: 0.7337 - accuracy: 0.7783 - val_loss: 0.6258 - val_accuracy: 0.8104 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "269/269 [==============================] - 388s 1s/step - loss: 0.7260 - accuracy: 0.7762 - val_loss: 0.6290 - val_accuracy: 0.8111 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "269/269 [==============================] - 385s 1s/step - loss: 0.7180 - accuracy: 0.7834 - val_loss: 0.6243 - val_accuracy: 0.8089 - lr: 1.0000e-04\n",
      "Epoch 17/30\n",
      "269/269 [==============================] - 380s 1s/step - loss: 0.7221 - accuracy: 0.7801 - val_loss: 0.6248 - val_accuracy: 0.8116 - lr: 1.0000e-04\n",
      "Epoch 18/30\n",
      "269/269 [==============================] - 384s 1s/step - loss: 0.7042 - accuracy: 0.7844 - val_loss: 0.6221 - val_accuracy: 0.8099 - lr: 1.0000e-04\n",
      "Epoch 19/30\n",
      "269/269 [==============================] - 383s 1s/step - loss: 0.6967 - accuracy: 0.7875 - val_loss: 0.6255 - val_accuracy: 0.8118 - lr: 1.0000e-04\n",
      "Epoch 20/30\n",
      "269/269 [==============================] - 382s 1s/step - loss: 0.6903 - accuracy: 0.7867 - val_loss: 0.6241 - val_accuracy: 0.8127 - lr: 1.0000e-04\n",
      "Epoch 21/30\n",
      "269/269 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.7868\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "269/269 [==============================] - 383s 1s/step - loss: 0.6934 - accuracy: 0.7868 - val_loss: 0.6302 - val_accuracy: 0.8087 - lr: 1.0000e-04\n",
      "Epoch 21: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs = 30,\n",
    "    steps_per_epoch = nb_train_samples//batch_size,\n",
    "    validation_data = valid_generator, \n",
    "    validation_steps = nb_valid_samples//batch_size,\n",
    "    callbacks = callbacks,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6de6c1a0-ac15-458a-b0ee-d940db4dd44d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45447,
     "status": "ok",
     "timestamp": 1654797776098,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "6de6c1a0-ac15-458a-b0ee-d940db4dd44d",
    "outputId": "2202fe10-4a32-40df-916d-f1a6ad00cbb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 45s 663ms/step - loss: 0.6287 - accuracy: 0.8087\n",
      "Validation Loss:  0.6287146210670471\n",
      "Validation Accuracy:  0.8086956739425659\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(eval_loss, eval_accuracy) = model.evaluate(valid_generator, batch_size= batch_size, verbose= 1)\n",
    "print('Validation Loss: ', eval_loss)\n",
    "print('Validation Accuracy: ', eval_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8160be75-f789-4c3f-b95e-3c3bafffb315",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 4801,
     "status": "ok",
     "timestamp": 1654797786079,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "8160be75-f789-4c3f-b95e-3c3bafffb315",
    "outputId": "94b91b92-3d7e-4340-bc05-8b68984f0d51"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot()\n",
    "plt.title('Model Accuracy')\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
    "plt.savefig('baseline_acc_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 900)\n",
    "plt.show()\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Training Loss','Validation Loss'])\n",
    "plt.savefig('baseline_loss_epoch.png', transparent= False, bbox_inches= 'tight', dpi= 900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "qoNkCCzztidA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44480,
     "status": "ok",
     "timestamp": 1654797839923,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "qoNkCCzztidA",
    "outputId": "8fdd552d-ab44-400d-e59b-845d92cf38c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./drive/MyDrive/dog_breed_classifier/model_data_softmax/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./drive/MyDrive/dog_breed_classifier/model_data_softmax/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eMh_4thp6s2",
   "metadata": {
    "id": "5eMh_4thp6s2"
   },
   "source": [
    "## Model Metrics Overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "oyKbT6Dsp-vF",
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1654798171004,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "oyKbT6Dsp-vF"
   },
   "outputs": [],
   "source": [
    "test_data_path = './Testing_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05fb27ad-f440-473b-a3ba-95966a6383c9",
   "metadata": {
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1654798171921,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "05fb27ad-f440-473b-a3ba-95966a6383c9"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255, \n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "mL4aPPuPplev",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1654798173328,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "mL4aPPuPplev",
    "outputId": "cdd8e514-6719-4fd2-a9e9-0f9628ec13fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3633 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size= (img_width, img_height),\n",
    "    color_mode= 'rgb',\n",
    "    batch_size= batch_size,  \n",
    "    class_mode= 'categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "i5q8LaqYqEHr",
   "metadata": {
    "executionInfo": {
     "elapsed": 37084,
     "status": "ok",
     "timestamp": 1654798876643,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "i5q8LaqYqEHr"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_generator)\n",
    "preds_encoded = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "xyoy1AansfEd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1654798876644,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "xyoy1AansfEd",
    "outputId": "54b57a97-13ea-4773-add7-8bc0aa569926"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 119,  26, 119])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "F0blsjWcqKYz",
   "metadata": {
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1654798734955,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "F0blsjWcqKYz"
   },
   "outputs": [],
   "source": [
    "label_names = list(test_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10OS7sm1sORl",
   "metadata": {
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1654798800643,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "10OS7sm1sORl"
   },
   "outputs": [],
   "source": [
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "DBWMboCasZ23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105,
     "status": "ok",
     "timestamp": 1654798905284,
     "user": {
      "displayName": "Luisa Gonzalez",
      "userId": "09172697332445122098"
     },
     "user_tz": 240
    },
    "id": "DBWMboCasZ23",
    "outputId": "4f870844-8372-4d04-9d07-d217542036bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                 Affenpinscher       0.76      1.00      0.87        13\n",
      "                        Afghan       0.98      0.98      0.98        50\n",
      "              African Wild Dog       0.98      1.00      0.99        50\n",
      "                      Airedale       0.92      0.92      0.92        50\n",
      "American Staffordshire Terrier       0.81      0.92      0.86        50\n",
      "                   Appenzeller       1.00      0.33      0.50        12\n",
      "            Australian Terrier       0.50      1.00      0.67        12\n",
      "                       Basenji       0.96      1.00      0.98        50\n",
      "                        Basset       0.98      0.96      0.97        50\n",
      "                        Beagle       0.94      0.94      0.94        50\n",
      "            Bedlington Terrier       1.00      1.00      1.00        13\n",
      "          Bernese Mountain Dog       1.00      0.96      0.98        50\n",
      "       Black-and-Tan Coonhound       0.71      0.91      0.80        11\n",
      "              Blenheim Spaniel       0.94      0.98      0.96        50\n",
      "                    Bloodhound       0.98      0.90      0.94        50\n",
      "                      Bluetick       0.94      0.92      0.93        50\n",
      "                 Border Collie       0.86      0.96      0.91        50\n",
      "                Border Terrier       0.91      0.91      0.91        11\n",
      "                        Borzoi       0.98      0.92      0.95        50\n",
      "                   Boston Bull       0.96      0.92      0.94        50\n",
      "          Bouvier Des Flandres       0.89      0.62      0.73        13\n",
      "                         Boxer       0.92      0.88      0.90        50\n",
      "             Brabancon Griffon       0.85      0.92      0.88        12\n",
      "                        Briard       0.85      0.92      0.88        12\n",
      "              Brittany Spaniel       0.50      0.45      0.48        11\n",
      "                  Bull Mastiff       0.82      0.92      0.87        50\n",
      "                         Cairn       0.91      0.98      0.94        50\n",
      "                      Cardigan       0.67      1.00      0.80        10\n",
      "      Chesapeake Bay Retriever       1.00      1.00      1.00        10\n",
      "                     Chihuahua       0.98      0.86      0.91        50\n",
      "                          Chow       1.00      0.98      0.99        50\n",
      "                       Clumber       0.96      0.98      0.97        50\n",
      "                Cocker Spaniel       0.98      0.40      0.57       102\n",
      "                        Collie       0.83      0.70      0.76        50\n",
      "        Curly Coated Retriever       0.50      1.00      0.67        13\n",
      "                Dandie Dinmont       0.79      1.00      0.88        11\n",
      "                         Dhole       1.00      0.96      0.98        50\n",
      "                         Dingo       0.98      0.92      0.95        50\n",
      "                      Doberman       0.82      0.94      0.88        50\n",
      "              English Foxhound       0.62      0.56      0.59         9\n",
      "                English Setter       0.67      0.91      0.77        11\n",
      "              English Springer       0.70      0.88      0.78         8\n",
      "                   Entlebucher       0.50      0.91      0.65        11\n",
      "                    Eskimo Dog       0.00      0.00      0.00        11\n",
      "         Flat Coated Retriever       0.59      0.91      0.71        11\n",
      "                French Bulldog       0.81      0.92      0.86        50\n",
      "               German Shepherd       0.84      0.94      0.89        50\n",
      "   German Short Haired Pointer       0.92      0.92      0.92        12\n",
      "               Giant Schnauzer       0.42      0.80      0.55        10\n",
      "              Golden Retriever       0.91      0.98      0.94        50\n",
      "                 Gordon Setter       0.92      1.00      0.96        11\n",
      "                    Great Dane       0.91      0.86      0.89        50\n",
      "                Great Pyrenees       0.97      0.76      0.85        50\n",
      "    Greater Swiss Mountain Dog       0.78      0.64      0.70        11\n",
      "                   Groenendael       0.98      0.96      0.97        50\n",
      "                  Ibizan Hound       0.79      1.00      0.88        11\n",
      "                  Irish Setter       0.80      1.00      0.89        12\n",
      "                 Irish Terrier       0.65      1.00      0.79        11\n",
      "           Irish Water Spaniel       0.76      1.00      0.86        50\n",
      "               Irish Wolfhound       0.96      0.50      0.66        50\n",
      "             Italian Greyhound       0.90      0.82      0.86        11\n",
      "              Japanese Spaniel       0.94      0.88      0.91        50\n",
      "                      Keeshond       0.92      1.00      0.96        11\n",
      "                        Kelpie       0.44      0.70      0.54        10\n",
      "            Kerry Blue Terrier       0.90      0.90      0.90        10\n",
      "                      Komondor       1.00      0.98      0.99        50\n",
      "                        Kuvasz       0.50      1.00      0.67        11\n",
      "            Labrador Retriever       0.98      0.94      0.96        50\n",
      "              Lakeland Terrier       0.67      0.40      0.50        10\n",
      "                      Leonberg       0.73      1.00      0.85        11\n",
      "                         Lhasa       0.65      0.48      0.55        50\n",
      "                      Malamute       0.80      0.73      0.76        11\n",
      "                      Malinois       0.98      0.82      0.89        50\n",
      "                       Maltese       0.92      0.94      0.93        50\n",
      "              Mexican Hairless       0.94      1.00      0.97        50\n",
      "              Miniature Poodle       0.38      0.77      0.51        13\n",
      "           Miniature Schnauzer       0.64      0.64      0.64        11\n",
      "                  Newfoundland       0.95      0.78      0.86        50\n",
      "               Norfolk Terrier       0.89      0.80      0.84        10\n",
      "            Norwegian Elkhound       1.00      0.94      0.97        50\n",
      "               Norwich Terrier       1.00      0.92      0.96        12\n",
      "          Old English Sheepdog       0.86      0.92      0.89        13\n",
      "                    Otterhound       0.69      1.00      0.81        11\n",
      "                      Papillon       0.92      1.00      0.96        12\n",
      "                      Pekinese       0.90      0.92      0.91        50\n",
      "                Pembroke Corgi       0.92      0.82      0.87        28\n",
      "                      Pinscher       0.50      0.30      0.37        10\n",
      "                    Pomeranian       1.00      0.98      0.99        50\n",
      "                           Pug       1.00      0.78      0.88        50\n",
      "                       Redbone       0.67      0.91      0.77        11\n",
      "           Rhodesian Ridgeback       0.88      0.74      0.80        50\n",
      "                    Rottweiler       0.98      0.96      0.97        50\n",
      "                 Saint Bernard       0.96      0.98      0.97        50\n",
      "                        Saluki       0.86      1.00      0.92        12\n",
      "                       Samoyed       0.56      1.00      0.72        14\n",
      "                    Schipperke       0.92      0.92      0.92        12\n",
      "                Scotch Terrier       1.00      0.89      0.94       150\n",
      "            Scottish Deerhound       0.37      0.93      0.53        14\n",
      "              Sealyham Terrier       0.92      0.92      0.92        12\n",
      "             Shetland Sheepdog       0.59      0.71      0.65        14\n",
      "                      Shih-Tzu       0.70      0.66      0.68        50\n",
      "                Siberian Husky       0.94      0.88      0.91        50\n",
      "                 Silky Terrier       0.00      0.00      0.00        12\n",
      "   Soft Coated Wheaten Terrier       0.70      0.58      0.64        12\n",
      "     Staffordshire Bullterrier       0.71      0.77      0.74        13\n",
      "               Standard Poodle       0.79      0.60      0.68        25\n",
      "            Standard Schnauzer       0.73      0.79      0.76        14\n",
      "                Sussex Spaniel       0.52      1.00      0.68        13\n",
      "               Tibetan Mastiff       0.73      0.92      0.81        12\n",
      "               Tibetan Terrier       0.42      0.79      0.55        14\n",
      "                    Toy Poodle       0.67      0.17      0.27        12\n",
      "                   Toy Terrier       0.62      0.71      0.67        14\n",
      "                        Vizsla       0.92      0.92      0.92        50\n",
      "                  Walker Hound       0.73      0.73      0.73        15\n",
      "                    Weimaraner       0.81      0.93      0.87        14\n",
      "        Welsh Springer Spaniel       0.74      0.93      0.82        15\n",
      "   West Highland White Terrier       0.89      0.94      0.91        17\n",
      "                       Whippet       0.86      0.75      0.80        16\n",
      "       Wire Haired Fox Terrier       0.88      0.94      0.91        16\n",
      "             Yorkshire Terrier       0.92      0.88      0.90        50\n",
      "\n",
      "                      accuracy                           0.86      3633\n",
      "                     macro avg       0.81      0.84      0.81      3633\n",
      "                  weighted avg       0.88      0.86      0.86      3633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, preds_encoded, target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02VwIimUuCdp",
   "metadata": {
    "id": "02VwIimUuCdp"
   },
   "source": [
    "This is a reliable model that is achieving high precision and high recal scores across 120 breeds. With several breeds, the model has a precision score of 1, and/or a recall score of 1. The accuracy score for the overall model is 0.86. Please refer to the next notebook for a misclassification analysis and next steps. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Model_Training_Softmax.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
